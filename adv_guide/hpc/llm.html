
<!DOCTYPE html>


<html lang="EN" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
    <link href="../../_static/favicon-32x32.png" rel="icon" type="image/png">
    <link href="../../_static/favicon-16x16.png" rel="icon" type="image/png">
    <link rel="shortcut icon" sizes="any" href="../../_static/favicon.ico" type="image/x-icon">
    <link href="../../_static/android-chrome-192x192.png" rel="icon" type="image/png">
    <link rel="mask-icon" color="#459db9" href="../../_static/safari-pinned-tab.svg" type="image/svg+xml">
    <link rel="apple-touch-icon" href="../../_static/apple-touch-icon.png" type="image/png">
    <meta name="msapplication-TileColor" content="#459db9">
    <meta name="theme-color" content="#ffffff">
    <meta name="msapplication-TileImage" content="mstile-150x150.png">
    <title>LLaMA &#8212; Exascale Knowledge Share 0.16.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Vibur" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyterlite_sphinx.css?v=8ee2c72c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=0f282c0f"></script>
    <script src="../../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/thebelab-helper.js"></script>
    <script src="../../_static/jupyterlite_sphinx.js?v=96e329c5"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=1ae7504c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'adv_guide/hpc/llm';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://pydata-sphinx-theme.readthedocs.io/en/latest/_static/switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'v0.16.1';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="EN"/>
  <meta name="docsearch:version" content="0.2" />
    <meta name="docbuild:last-update" content="Feb 13, 2026"/>   
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
  <aside class="bd-header-announcement d-print-none d-none" aria-label="Announcement" data-pst-announcement-url="https://raw.githubusercontent.com/pydata/pydata-sphinx-theme/main/docs/_templates/custom-template.html"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/mai_logo.jpeg" class="logo__image only-light" alt="MAI - Home"/>
    <img src="../../_static/mai_logo.jpeg" class="logo__image only-dark pst-js-only" alt="MAI - Home"/>
  
  
    <p class="title logo__title">Exascale Knowledge Share</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index.html">
    User Guides
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../application/index.html">
    APPLICATION
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contb_guide/index.html">
    Contribution Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../sys_oview/index.html">
    Node Configuration
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/pydata/pydata-sphinx-theme/releases">
    Changelog
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ai-hpc-mu/document" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github-square fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index.html">
    User Guides
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../application/index.html">
    APPLICATION
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contb_guide/index.html">
    Contribution Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../sys_oview/index.html">
    Node Configuration
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/pydata/pydata-sphinx-theme/releases">
    Changelog
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ai-hpc-mu/document" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-github-square fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"></div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">LLaMA</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                   <p>Large language model (LLM) is a language model notable for its ability to achieve general-purpose language generation. LLMs acquire these abilities by learning statistical relationships from text documents during a computationally intensive self-supervised and semi-supervised training process. LLMs are artificial neural networks typically built with a transformer-based architecture. Some recent implementations are based on alternative architectures such as recurrent neural network variants and Mamba (a state space model).</p>
<p>LLMs can be used for text generation, a form of generative AI, by taking an input text and repeatedly predicting the next token or word. Up to 2020, fine tuning was the only way a model could be adapted to be able to accomplish specific tasks. Larger sized models, such as GPT-3, however, can be prompt-engineered to achieve similar results. They are thought to acquire knowledge about syntax, semantics and “ontology” inherent in human language corpora, but also inaccuracies and biases present in the corpora.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Large_language_model">Large language model</a></p>
<section id="llama">
<h1>LLaMA<a class="headerlink" href="#llama" title="Link to this heading">#</a></h1>
<p>The first LLM open model we are interested is LLaMA that OpenThaiGPT based on this model.
LLaMA (Large Language Model Meta AI) is a family of autoregressive large language models (LLMs), released by Meta AI starting in February 2023.
<cite>OpenThaiGPT Finetune &lt;https://github.com/OpenThaiGPT/openthaigpt-finetune&gt;</cite></p>
</section>
<section id="lora-ai-at-the-edge-is-comming">
<h1>LoRA: AI at the edge is comming.<a class="headerlink" href="#lora-ai-at-the-edge-is-comming" title="Link to this heading">#</a></h1>
<p>However, after we proved that we can make use resource to finetune LLaMa model in one night one A100 server, answer for Thai language is more room to improve. So with LoRA or Low-Rank Adaptation method is a fine-tuning method introduced by a team of Microsoft researchers in 2021. Since then, it has become a very popular approach to fine-tuning large language models. It makes possible edge resource to finetune LLM.</p>
</section>
<section id="goolge-s-llm-gemma">
<h1>Goolge’s LLM: Gemma<a class="headerlink" href="#goolge-s-llm-gemma" title="Link to this heading">#</a></h1>
<p>There are LLM model from Goolge, the lastest one is Gemma. Google has unveiled Gemma, a collection of lightweight, open-source AI models, following the triumph of their flagship Gemini models. Gemma targets developers aiming to integrate AI capabilities into their applications, unlike Gemini, which primarily serves end-users via platforms like search engines or virtual assistants or prompt engineering.</p>
</section>
<section id="responsible-ai">
<h1>Responsible AI<a class="headerlink" href="#responsible-ai" title="Link to this heading">#</a></h1>
<p>There are many feature that suitable for developer to start working on LLM with challenge resource. The following are main features of Gemma:
- Lightweight: Unlike Gemini, Gemma models are compact and can operate on laptops, desktops, and IoT devices, without hefty computing requirements
- Responsible AI Toolkit: Developers receive a Responsible Generative AI Toolkit alongside Gemma models, facilitating the creation of safer AI applications.
- Closed Model versus Open Source: Gemini is closed-source, while Gemma is open-source, granting developers more freedom and control.
- Target Audience: Gemini targets general consumers, whereas Gemma caters to developers seeking to integrate AI features
- Adaptability: Gemma allows for high adaptability, enabling developers to fine-tune models for specific tasks or datasets.</p>
<section id="inference-gemma-on-dgx-a100">
<h2>Inference Gemma on DGX A100:<a class="headerlink" href="#inference-gemma-on-dgx-a100" title="Link to this heading">#</a></h2>
<p>To test feature of Gemma model and tools, the model and Singularity image is provide for AI developer to apply for projects.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>salloc<span class="w"> </span>-w<span class="w"> </span>omega<span class="w"> </span>-t<span class="w"> </span><span class="m">1</span>:0:0<span class="w"> </span>--gres<span class="o">=</span>gpu:1
</pre></div>
</div>
<p>Assume you get resource compute node.
In case you got many gpus, specify which one you will use.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">export CUDA_VISIBLE_DEVICES=1</span>
</pre></div>
</div>
<p>Set up environment</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">export PROMPT=&quot;ความหมาย ของ ชีวิตคืออะไร&quot;</span>
<span class="go">export VARIANT=7b</span>
<span class="go">export  CKPT_PATH=/shared/models/Gemma/ckpt/${VARIANT}</span>
</pre></div>
</div>
<p>Execute Pyton script to run interference in singularity image</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">singularity run --nv -B ${CKPT_PATH}:&quot;/tmp/ckpt&quot; /app/gemma.sif python scripts/run.py  --device=cuda  --ckpt=/tmp/ckpt/gemma-${VARIANT}.ckpt --variant=${VARIANT}  --prompt=&quot;${PROMPT}&quot;</span>
</pre></div>
</div>
</section>
<section id="get-up-and-running-with-large-language-models-on-private-cloud">
<h2>Get up and running with large language models on private cloud<a class="headerlink" href="#get-up-and-running-with-large-language-models-on-private-cloud" title="Link to this heading">#</a></h2>
<p>Serving large language models (LLMs) locally can be super helpful—whether you’d like to play around with LLMs or build more powerful apps using them. But configuring your working environment and getting LLMs to run on your machine is not trivial.</p>
<p>So how do you run LLMs locally or on primise cloud without any of the annoyance? Enter Ollama, a platform that makes local development with open-source large language models. With Ollama, everything you need to run an LLM—model weights and all of the config—is packaged into a single Modelfile. Think kubernetes for LLMs.</p>
<p>In this tutorial, we’ll take a look at how to get started with Ollama to run large language models on AI/HPC cluster . So let’s get right into the steps!</p>
</section>
</section>
<section id="get-source-repository-and-make-them-work-on-k8s-for-ollama">
<h1>Get Source repository and make them work on K8S  for Ollama<a class="headerlink" href="#get-source-repository-and-make-them-work-on-k8s-for-ollama" title="Link to this heading">#</a></h1>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w">  </span>clone<span class="w"> </span>https://github.com/ollama/ollama.git

<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>~/ollama/examples/kubernetes/
</pre></div>
</div>
<p>Modify gpu.yaml to your with your namespace.
With follow step replace the correct namespace.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>gpu.yaml

<span class="gp">$ </span>kubectl<span class="w"> </span>-n<span class="w"> </span>ollama<span class="w"> </span>port-forward<span class="w"> </span>service/ollama<span class="w"> </span><span class="m">11434</span>:80

<span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>pod<span class="w"> </span>-n<span class="w"> </span>ollama
</pre></div>
</div>
<p>Connect to pod and pull LLM models as your want to use.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl<span class="w"> </span>-n<span class="w"> </span>ollama<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--stdin<span class="w"> </span>--tty<span class="w"> </span>ollama-58fcd9f74d-8rp92<span class="w">  </span>--<span class="w"> </span>/bin/bash

<span class="gp"># </span>ollama<span class="w"> </span>pull<span class="w"> </span>gemma2

<span class="gp"># </span>ollama<span class="w"> </span>pull<span class="w"> </span>llama3.1:405b
</pre></div>
</div>
<p>Test on the server inside Pod:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>ollama<span class="w"> </span>run<span class="w"> </span>gemma2<span class="w"> </span><span class="s2">&quot;How should Mahidol University do to be favorite place for researcher around the world in next 20 years?&quot;</span>
</pre></div>
</div>
</section>
<section id="restapi-test-on-host-that-port-forwarded">
<h1>RestAPI test on host that port forwarded<a class="headerlink" href="#restapi-test-on-host-that-port-forwarded" title="Link to this heading">#</a></h1>
<p>On host that we set up port forward for ollama service, we can test RestAPI for model response.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl<span class="w"> </span>--noproxy<span class="w"> </span><span class="s2">&quot;*&quot;</span><span class="w">  </span>http://127.0.0.1:11434/api/generate<span class="w"> </span>-d<span class="w"> </span><span class="err">&#39;</span><span class="o">{</span>
<span class="go">   &quot;model&quot;: &quot;gemma2&quot;,</span>
<span class="go">   &quot;prompt&quot;: &quot;มหาวิทยาลัยมหิดลจะนำผู้คนในประเทศ ไปสู่ยุ่คใหม่ ปี 2050 มหาวิทยาลัยควรมีบทบาทอะไร ที่สำคับเจ็ดด้านหลักๆ&quot;</span>
<span class="go"> }&#39;</span>
</pre></div>
</div>
<section id="new-llama-3-1-now-suport-thai">
<h2>New LLaMa 3.1 NOW suport Thai<a class="headerlink" href="#new-llama-3-1-now-suport-thai" title="Link to this heading">#</a></h2>
</section>
</section>
<section id="multi-lingual-capabilities-in-llama3-1-405b">
<h1>Multi-lingual capabilities in Llama3.1 405B<a class="headerlink" href="#multi-lingual-capabilities-in-llama3-1-405b" title="Link to this heading">#</a></h1>
<p>The main update from Llama 3 to Llama 3.1 is better non-English support. The training data for Llama 3 was 95% English, so it performed poorly in other languages. The 3.1 update provides support for German, French, Italian, Portuguese, Hindi, Spanish, and Thai.
.. role:: thai
.. code-block:: console</p>
<blockquote>
<div><p>$ curl   -L <a class="reference external" href="https://mai">https://mai</a>:&lt;ictCallNumber&gt;&#64;aicenter.mahidol.ac.th/ollama/api/generate -d ‘{“model”: “llama3.1”, “prompt”:”วันอาทิตย์พักผ่อนที่ไหนดี”}’</p>
</div></blockquote>
<p>Deployment  on Exascale cluster, ingress proxy have been  verified.
It is tested with basic authentication.</p>
</section>
<section id="api-inferencing-check-available-model">
<h1>API inferencing check  available model :<a class="headerlink" href="#api-inferencing-check-available-model" title="Link to this heading">#</a></h1>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl<span class="w">   </span>-L<span class="w"> </span>https://mai:&lt;ictCallNumber@aicenter.mahidol.ac.th/ollama/api/tags<span class="s2">&quot;}&#39;</span>
</pre></div>
</div>
<p><a class="reference external" href="https://github.com/ollama/ollama/blob/main/docs/api.md#list-local-models">API document</a></p>
<p>Reference:</p>
<p><a class="reference external" href="https://ollama.com/">Get up and running with Large language model</a>
<a class="reference external" href="https://www.datacamp.com/blog/llama-3-1-405b-meta-ai">What Is Llama 3.1 405B?</a></p>
<section id="build-llm-apps-with-low-code">
<h2>Build LLM Apps with Low-code<a class="headerlink" href="#build-llm-apps-with-low-code" title="Link to this heading">#</a></h2>
<p>With serving LLM model, we can build AI applications that applied  models with low-code tool for developers to build customized LLM orchestration flow &amp; AI agents.</p>
<p><a class="reference external" href="https://flowiseai.com/">Build LLM Application with FlowiseAI</a></p>
</section>
</section>

<div class="section ablog__blog_comments">
   
</div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">LLaMA</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#lora-ai-at-the-edge-is-comming">LoRA: AI at the edge is comming.</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#goolge-s-llm-gemma">Goolge’s LLM: Gemma</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#responsible-ai">Responsible AI</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-gemma-on-dgx-a100">Inference Gemma on DGX A100:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-up-and-running-with-large-language-models-on-private-cloud">Get up and running with large language models on private cloud</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#get-source-repository-and-make-them-work-on-k8s-for-ollama">Get Source repository and make them work on K8S  for Ollama</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#restapi-test-on-host-that-port-forwarded">RestAPI test on host that port forwarded</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-llama-3-1-now-suport-thai">New LLaMa 3.1 NOW suport Thai</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-lingual-capabilities-in-llama3-1-405b">Multi-lingual capabilities in Llama3.1 405B</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#api-inferencing-check-available-model">API inferencing check  available model :</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-llm-apps-with-low-code">Build LLM Apps with Low-code</a></li>
</ul>
</li>
</ul>

  </nav></div>

  <div class="sidebar-secondary-item">
  
  <div class="tocsection editthispage">
    <a href="https://github.com/pydata/pydata-sphinx-theme/edit/main/docs/adv_guide/hpc/llm.rst">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/adv_guide/hpc/llm.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2025, MAI.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 9.1.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>