

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Software Guide &mdash; Exascale Knowledge Share 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=2709fde1"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Electrical Energy Saving" href="powersaving.html" />
    <link rel="prev" title="Workshop" href="workshop.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Exascale Knowledge Share
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="home.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickStart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="alphafold.html">AlphaFold 3 :  The inference pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="mathphysic.html">Mathematical modeling in Physics Engineering, Biological and Social Science with QwQ LLM from China</a></li>
<li class="toctree-l1"><a class="reference internal" href="rstudio.html">Mathematics and Statistics Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="wine.html">Excel Macro Runner Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="container.html">Apptainer/Singularity</a></li>
<li class="toctree-l1"><a class="reference internal" href="workshop.html">Workshop</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Software Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#rna-and-chip-sequencing-analysis">RNA and ChIP-sequencing analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#single-particle-analysis">Single Particle Analysis:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#software-define-radio-and-cloud-radio-access-network">Software Define Radio and Cloud Radio Access Network:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#macromolecular-modeling-and-visualization">Macromolecular Modeling and Visualization:</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#amber">Amber:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#vmd">VMD:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#gromacs-high-performance-molecular-dynamics">GROMACS: High Performance Molecular Dynamics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#example-gromacs-on-4-gpus-128cpu-mpis">Example GROMACS on 4 GPUs 128CPU  MPIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#download-benchmark-dataset">Download Benchmark Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#run-on-singularity">Run on Singularity:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#performance-x-2-with-direct-gpus-nvlink">Performance x 2 with Direct GPUs NVLINK</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#pilot-test-cluster-access-and-performance-awareness">Pilot Test: Cluster Access and Performance Awareness:</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#given-test-at">Given Test at:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#features">Features:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#principal-investigators-pis-or-project-owners">Principal investigators (PIs) or Project Owners:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hpc-system-administrators">HPC system administrators:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#center-directors">Center directors:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="powersaving.html">Electrical Energy  Saving</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantumml.html">Quantum Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_multi.html">Pytorch DISTRIBUTED DATA PARALLEL</a></li>
<li class="toctree-l1"><a class="reference internal" href="parabricks.html">NVIDIA Parabricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="cryo_em.html">Cryogenic electron microscopy</a></li>
<li class="toctree-l1"><a class="reference internal" href="cryo_em.html#relion-4-0-for-cryo-em-structure-determination">Relion 4.0 for cryo-EM structure determination</a></li>
<li class="toctree-l1"><a class="reference internal" href="cryo_em.html#computational-imaging-system-for-transmission-electron-microscopy-cistem">Computational Imaging System for Transmission Electron Microscopy(cisTEM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm.html">LLaMA</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm.html#lora-ai-at-the-edge-is-comming">LoRA: AI at the edge is comming.</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm.html#goolge-s-llm-gemma">Goolge’s LLM: Gemma</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm.html#responsible-ai">Responsible AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm.html#get-source-repository-and-make-them-work-on-k8s-for-ollama">Get Source repository and make them work on K8S  for Ollama</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm.html#restapi-test-on-host-that-port-forwarded">RestAPI test on host that port forwarded</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm.html#multi-lingual-capabilities-in-llama3-1-405b">Multi-lingual capabilities in Llama3.1 405B</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm.html#api-inferencing-check-available-model">API inferencing check  available model :</a></li>
<li class="toctree-l1"><a class="reference internal" href="e4s.html">Extreme-scale Scientific Software Stack (E4S)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bioinfo.html">Biomedical Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="bioinfo.html#reproducting-research-results-with-python-and-conda-package-management">Reproducting research results with Python and Conda Package management</a></li>
<li class="toctree-l1"><a class="reference internal" href="bioinfo.html#nextflow-reproducible-scientific-workflows">Nextflow:Reproducible scientific workflows</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Exascale Knowledge Share</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Software Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/swguide.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="software-guide">
<h1>Software Guide<a class="headerlink" href="#software-guide" title="Link to this heading"></a></h1>
<p>The following guides are intend to introduce basic tools for HPC Bioinformatics tools.</p>
<section id="rna-and-chip-sequencing-analysis">
<h2>RNA and ChIP-sequencing analysis<a class="headerlink" href="#rna-and-chip-sequencing-analysis" title="Link to this heading"></a></h2>
<p><a class="reference external" href="https://github.com/vclabsysbio/AI-MD_RNASeq_ChIPseq">RNASeq ChIPseq</a></p>
<p><a class="reference external" href="https://github.com/vclabsysbio/AI-MD_scRNAseq">Single-cell RNA-seq</a></p>
</section>
<section id="single-particle-analysis">
<h2>Single Particle Analysis:<a class="headerlink" href="#single-particle-analysis" title="Link to this heading"></a></h2>
<p>relion (for REgularised LIkelihood OptimisatioN, pronounce rely-on) is a software package that employs an empirical Bayesian approach for electron cryo-microscopy (cryo-EM) structure determination. It is developed in the group of Sjors Scheres at the <a class="reference external" href="https://relion.readthedocs.io/en/release-4.0/index.html">MRC Laboratory of Molecular Biology</a></p>
<p>Allocate resource for one compute node.
Benchmark result compare to RTX3090 time reduced from 72 minutes to 30 minutes</p>
<p><a class="reference external" href="https://www.linuxvixion.com/blog/relion-fastest-ever-benchmark/">RTX3090 and V100 Benchmark</a></p>
<p>Console:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cp /shared/dataset/relion/relion_benchmark ~/fastdata -r
$ cd ~/fastdata/relion_benchmark
$ singularity run --nv -B $PWD:/host_pwd --pwd /host_pwd /shared/software/singularity/images/relion_3.1.3.sif ./run_relion.sh
</pre></div>
</div>
</section>
<section id="software-define-radio-and-cloud-radio-access-network">
<h2>Software Define Radio and Cloud Radio Access Network:<a class="headerlink" href="#software-define-radio-and-cloud-radio-access-network" title="Link to this heading"></a></h2>
<p>GNU Radio is a free &amp; open-source software development toolkit that provides signal processing blocks to implement software radios. It can be used with readily-available low-cost external RF hardware to create software-defined radios, or without hardware in a simulation-like environment. It is widely used in research, industry, academia, government, and hobbyist environments to support both wireless communications research and real-world radio systems.</p>
<p><a class="reference external" href="https://https://www.gnuradio.org/">GNURadio</a></p>
<p>Console:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ salloc -w turing -t 1:0:0 -c 8 --mem=16G --gres=gpu:1
$ ssh turing
$ singularity shell --nv /app/gnuradio-3.10.sif
$ gnuradio-companion &amp;
</pre></div>
</div>
</section>
</section>
<section id="macromolecular-modeling-and-visualization">
<h1>Macromolecular Modeling and Visualization:<a class="headerlink" href="#macromolecular-modeling-and-visualization" title="Link to this heading"></a></h1>
<p>Biomolecular simulation</p>
<section id="amber">
<h2>Amber:<a class="headerlink" href="#amber" title="Link to this heading"></a></h2>
<p>Amber is the collective name for a suite of programs that allow users to carry out molecular dynamics simulations, particularly on biomolecules. The Amber software suite is divided into two parts: AmberTools23, a collection of freely available programs mostly under the GPL license, and Amber22, which is centered around the pmemd simulation  program, and which continues to be licensed as before, under a more restrictive license.</p>
<p>AmberTools is a set of programs for biomolecular simulation and analysis. They are designed to work well with each other, and with the “regular” Amber suite of programs. You can perform many simulation tasks with AmberTools, and you can do more extensive simulations with the combination of AmberTools and Amber itself. Most components of AmberTools are released under the GNU General Public License (GPL). A few components
are in the public domain or have other open-source licenses.</p>
<p><a class="reference external" href="https://ambermd.org/index.php">The Ameber Chemistry through a Computational Lens</a></p>
<p><a class="reference external" href="https://snitgit.github.io/MolecularSim-Amber-lesson/">Running Molecular Dynamics on Exascale AI/HPC Mahidol University Cluster with AMBER</a></p>
<p>Console:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ singularity shell --nv /app/amber22T23.sif
Singularity&gt; source /opt/amber22/amber.sh
Singularity&gt; tleap -f leaprc.protein.ff19SB
-I: Adding /opt/amber22/dat/leap/prep to search path.
-I: Adding /opt/amber22/dat/leap/lib to search path.
-I: Adding /opt/amber22/dat/leap/parm to search path.
-I: Adding /opt/amber22/dat/leap/cmd to search path.
-f: Source leaprc.protein.ff19SB.

Welcome to LEaP!
(no leaprc in search path)
Sourcing: /opt/amber22/dat/leap/cmd/leaprc.protein.ff19SB
Log file: ./leap.log
Loading parameters: /opt/amber22/dat/leap/parm/parm19.dat
Reading title:
PARM99 + frcmod.ff99SB + frcmod.parmbsc0 + OL3 for RNA + ff19SB
Loading parameters: /opt/amber22/dat/leap/parm/frcmod.ff19SB
Reading force field modification type file (frcmod)
Reading title:
ff19SB AA-specific backbone CMAPs for protein 07/25/2019
Loading library: /opt/amber22/dat/leap/lib/amino19.lib
Loading library: /opt/amber22/dat/leap/lib/aminoct12.lib
Loading library: /opt/amber22/dat/leap/lib/aminont12.lib
&gt; s = loadpdb protein.pdb
Loading PDB file: ./protein.pdb
-- residue 20: duplicate [ CG] atoms (total 2)
-- residue 20: duplicate [ OD1] atoms (total 2)
-- residue 20: duplicate [ OD2] atoms (total 2)
-- residue 43: duplicate [ CD2] atoms (total 2)
-- residue 43: duplicate [ CE1] atoms (total 2)
-- residue 43: duplicate [ CG] atoms (total 2)
-- residue 43: duplicate [ ND1] atoms (total 2)
-- residue 43: duplicate [ NE2] atoms (total 2)
-- residue 90: duplicate [ OG] atoms (total 2)

Warning: Atom names in each residue should be unique.
     (Same-name atoms are handled by using the first
      occurrence and by ignoring the rest.
      Many instances of duplicate atom names usually come
      from alternate conformations in the PDB file.)

  total atoms in file: 830
 Leap added 811 missing atoms according to residue templates:
    811 H / lone pairs
&gt; set {s.20 s.26} name &quot;ASH&quot;
&gt; savepdb s protonated.pdb
Writing pdb file: protonated.pdb

Warning:  Converting N-terminal residue name to PDB format: NMET -&gt; MET

Warning:  Converting C-terminal residue name to PDB format: CVAL -&gt; VAL
&gt; quit
Exiting LEaP: Errors = 0; Warnings = 3; Notes = 0.
Singularity&gt;
</pre></div>
</div>
<dl class="simple">
<dt><a class="reference external" href="https://ambermd.org/GetAmber.php">License</a></dt><dd><p>Getting Amber22 for commerical use</p>
</dd>
</dl>
<p>The license above is valid for both commerical and non-commerical usage. Only the license fee is different from commerical use. Commerical users should fill out this application for a commerical license. This will generate a license form that you can sign, and will contain information about how to pay the license fee.</p>
</section>
<section id="vmd">
<h2>VMD:<a class="headerlink" href="#vmd" title="Link to this heading"></a></h2>
<p>VMD is designed for modeling, visualization, and analysis of biological systems such as proteins, nucleic acids, lipid bilayer assemblies, etc. It may be used to view more general molecules, as VMD can read standard Protein Data Bank (PDB) files and display the contained structure. VMD provides a wide variety of methods for rendering and coloring a molecule: simple points and lines, CPK spheres and cylinders, licorice bonds, backbone tubes and ribbons, cartoon drawings, and others. VMD can be used to animate and analyze the trajectory of a molecular dynamics (MD) simulation. In particular, VMD can act as a graphical front end for an external MD program by displaying and animating a molecule undergoing simulation on a remote computer.</p>
<p><a class="reference external" href="https://www.ks.uiuc.edu/Research/vmd/">Theoretical and Computational BioPhysics</a></p>
<p>Console:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ singularity shell --nv /app/vmd1.9.4.sif
Singularity&gt; vmd
rlwrap: Command not found.
Info) VMD for LINUXAMD64, version 1.9.4a44 (June 22, 2020)
Info) http://www.ks.uiuc.edu/Research/vmd/
Info) Email questions and bug reports to vmd@ks.uiuc.edu
Info) Please include this reference in published work using VMD:
Info)    Humphrey, W., Dalke, A. and Schulten, K., `VMD - Visual
Info)    Molecular Dynamics&#39;, J. Molec. Graphics 1996, 14.1, 33-38.
Info) -------------------------------------------------------------
Info) Multithreading available, 256 CPUs detected.
Info)   CPU features: SSE2 AVX AVX2 FMA
Info) Free system memory: 980GB (97%)
Info) Creating CUDA device pool and initializing hardware...
Info) Unable to load NVML library, GPU-CPU affinity unavailable.
Info) Detected 8 available CUDA accelerators, 28 P2P links, 1 island:
Info) [0-7] NVIDIA A100-SXM4-40GB 108 SM_8.0 1.4 GHz, 40GB RAM AE3 ZC
Info) Detected 8 available TachyonL/OptiX ray tracing accelerators
Info)   Compiling 1 OptiX shaders on 8 target GPUs...
Info) Dynamically loaded 3 plugins in directory:
Info) /usr/local/lib/vmd/plugins/LINUXAMD64/molfile
vmd &gt;
vmd &gt; mol new protein.pdb
Info) Using plugin pdb for structure file protein.pdb
Info) Using plugin pdb for coordinates from file protein.pdb
Info) Determining bond structure from distance search ...
Info) Analyzing structure ...
Info)    Atoms: 830
Info)    Bonds: 846
Info)    Angles: 0  Dihedrals: 0  Impropers: 0  Cross-terms: 0
Info)    Bondtypes: 0  Angletypes: 0  Dihedraltypes: 0  Impropertypes: 0
Info)    Residues: 105
Info)    Waters: 0
Info)    Segments: 1
Info)    Fragments: 1   Protein: 1   Nucleic: 0
Info) Finished with coordinate file protein.pdb.
vmd &gt; set s [atomselect top &quot;resid 20 26&quot;]
atomselect0
vmd &gt; $s set resname ASH
vmd &gt; set s [atomselect top all]
atomselect1
vmd &gt; $s writepdb protonated.pdb
Info) Opened coordinate file protonated.pdb for writing.
Info) Finished with coordinate file protonated.pdb.
vmd &gt; quit
Info) VMD for LINUXAMD64, version 1.9.4a44 (June 22, 2020)
Info) Exiting normally.
Singularity&gt;
</pre></div>
</div>
</section>
</section>
<section id="gromacs-high-performance-molecular-dynamics">
<h1>GROMACS: High Performance Molecular Dynamics<a class="headerlink" href="#gromacs-high-performance-molecular-dynamics" title="Link to this heading"></a></h1>
<p>GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles and is a community-driven project. It is primarily designed for biochemical molecules like proteins, lipids and nucleic acids that have a lot of complicated bonded interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers and fluid dynamics.
<a class="reference external" href="https://www.gromacs.org/">https://www.gromacs.org/</a></p>
<section id="example-gromacs-on-4-gpus-128cpu-mpis">
<h2>Example GROMACS on 4 GPUs 128CPU  MPIs<a class="headerlink" href="#example-gromacs-on-4-gpus-128cpu-mpis" title="Link to this heading"></a></h2>
<p>The following examples demonstrate using the NGC GROMACS container to run the STMV benchmark. Reference performance, on a range of systems,
we use 2 thread-MPI tasks per GPU (-ntmpi 8), which we find gives good performance. We set 16 OpenMP threads per thread-MPI task (assuming at least 128 CPU cores in the system).</p>
</section>
<section id="download-benchmark-dataset">
<h2>Download Benchmark Dataset<a class="headerlink" href="#download-benchmark-dataset" title="Link to this heading"></a></h2>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">wget https://zenodo.org/record/3893789/files/GROMACS_heterogeneous_parallelization_benchmark_info_and_systems_JCP.tar.gz</span>

<span class="go">tar xf GROMACS_heterogeneous_parallelization_benchmark_info_and_systems_JCP.tar.gz</span>

<span class="go">cd GROMACS_heterogeneous_parallelization_benchmark_info_and_systems_JCP/stmv</span>
</pre></div>
</div>
</section>
<section id="run-on-singularity">
<h2>Run on Singularity:<a class="headerlink" href="#run-on-singularity" title="Link to this heading"></a></h2>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>salloc<span class="w">  </span>-t<span class="w"> </span><span class="m">1</span>:0:0<span class="w"> </span>-c<span class="w"> </span><span class="m">128</span><span class="w"> </span>--gres<span class="o">=</span>gpu:4

<span class="gp">$ </span>ssh<span class="w"> </span>&lt;computer<span class="w"> </span>node,<span class="w"> </span>allocate&gt;

<span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">GMX_ENABLE_DIRECT_GPU_COMM</span><span class="o">=</span><span class="m">1</span>

<span class="gp">$ </span>singularity<span class="w"> </span>run<span class="w"> </span>--nv<span class="w"> </span>-B<span class="w"> </span><span class="si">${</span><span class="nv">PWD</span><span class="si">}</span>:/host_pwd<span class="w"> </span>--pwd<span class="w"> </span>/host_pwd<span class="w"> </span>/app/gromacs.2023.2.sif<span class="w"> </span>gmx<span class="w"> </span>mdrun<span class="w"> </span>-ntmpi<span class="w"> </span><span class="m">8</span><span class="w"> </span>-ntomp<span class="w"> </span><span class="m">16</span><span class="w"> </span>-nb<span class="w"> </span>gpu<span class="w"> </span>-pme<span class="w"> </span>gpu<span class="w"> </span>-npme<span class="w"> </span><span class="m">1</span><span class="w"> </span>-update<span class="w"> </span>gpu<span class="w"> </span>-bonded<span class="w"> </span>gpu<span class="w"> </span>-nsteps<span class="w"> </span><span class="m">100000</span><span class="w"> </span>-resetstep<span class="w"> </span><span class="m">90000</span><span class="w"> </span>-noconfout<span class="w"> </span>-dlb<span class="w"> </span>no<span class="w"> </span>-nstlist<span class="w"> </span><span class="m">300</span><span class="w"> </span>-pin<span class="w"> </span>on<span class="w"> </span>-v<span class="w"> </span>-gpu_id<span class="w"> </span><span class="m">0123</span>
</pre></div>
</div>
</section>
<section id="performance-x-2-with-direct-gpus-nvlink">
<h2>Performance x 2 with Direct GPUs NVLINK<a class="headerlink" href="#performance-x-2-with-direct-gpus-nvlink" title="Link to this heading"></a></h2>
<p>Why not supercompuer!.</p>
<p>With normal communication link, performance GROMACS for overriding nsteps with value passed on the command line: 100000 steps, 200 ps</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">_               Core t (s)   Wall t (s)        (%)</span>
<span class="go">Time:           6561.962       51.310        12788.8</span>
<span class="go">                 (ns/day)    (hour/ns)</span>
<span class="go">Performance:       33.681        0.713</span>
</pre></div>
</div>
<p>After taking advantage of NVLINK Speed GPUs network directly</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">_             Core t (s)    Wall t (s)        (%)</span>
<span class="go">Time:         2796.036       21.914        12759.0</span>
<span class="go">                (ns/day)    (hour/ns)</span>
<span class="go">Performance:      78.861        0.304</span>
</pre></div>
</div>
</section>
</section>
<section id="pilot-test-cluster-access-and-performance-awareness">
<h1>Pilot Test: Cluster Access and Performance Awareness:<a class="headerlink" href="#pilot-test-cluster-access-and-performance-awareness" title="Link to this heading"></a></h1>
<p>PI has degree of freedom to manage your own project resource: User and Performance.
Computational Research Center automatic get update publications.</p>
<p>Inspired by incomming Indonesia visiting for Performance Benchmarking, we create testbed to demonstrate how three open source applications work in concert to provide a <strong>toolset for high performance computing (HPC) centers</strong>. <strong>ColdFront</strong> is an <strong>allocations management portal</strong> that provides users an easy way to request access to allocations for a Center’s resources. HPC systems staff configure the data center’s resources with attributes that tie ColdFront’s plug-ins to systems such as job schedulers, authentication/account management systems, system monitoring, and <strong>Open XDMoD</strong>. Once the user’s allocation is activated in ColdFront, they are able to access the resource using <strong>Open OnDemand</strong>, a web-based portal for accessing HPC services that removes the complexities of HPC system environments from the end-user. Through Open OnDemand, users can upload and download files, create, edit, submit and monitor jobs, create and share apps, run GUI applications and connect to a terminal, all via a web browser, with no client software to install and configure. The <strong>Open XDMoD</strong> portal provides a rich set of features, which are tailored to the role of the user. Sample metrics provided by Open XDMoD include: number of jobs, CPUs consumed, wait time, and wall time, with minimum, maximum and the average of these metrics. Performance and quality of service metrics of the HPC infrastructure are also provided, along with application specific performance metrics (flop/s, IO rates, network metrics, etc) for all user applications running on a given resource.</p>
<p><a class="reference external" href="https://www.buffalo.edu/ccr/about-us/news-events/latest_news.host.html/content/shared/www/ccr/ccr-news/nsf-grant-awarded-in-collaboration-with-osc.detail.html">NSF grant awarded in collaboration with OSC &amp; VT</a></p>
<p><strong>PI</strong> has degree of freedom to manage your own project resource: <strong>User and reasonable  Performance utilization</strong>.
<strong>Computational Research Center</strong> automatic get update publications.</p>
<section id="given-test-at">
<h2>Given Test at:<a class="headerlink" href="#given-test-at" title="Link to this heading"></a></h2>
<blockquote>
<div><p>Coldfront URL: <a class="reference external" href="https://10.34.250.32:2443">https://10.34.250.32:2443</a></p>
<p>OnDemand URL: <a class="reference external" href="https://10.34.250.32:3443">https://10.34.250.32:3443</a></p>
<p>XDMoD URL: <a class="reference external" href="https://10.34.250.32:4443">https://10.34.250.32:4443</a></p>
<p>User: cgray
pass: test123</p>
<p>Test for <strong>Future HPC admin workshop</strong> and <a href="#id1"><span class="problematic" id="id2">**</span></a>if we use these plateform for access and monitor their job, what is users feedback?</p>
</div></blockquote>
</section>
<section id="features">
<h2>Features:<a class="headerlink" href="#features" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Allocation based system for managing access to resources</p></li>
<li><p>Self-service portal for users to request access to resources for their research group</p></li>
<li><p>Collection of Project, Grant, and Publication data from users</p></li>
<li><p>Center director approval system and annual project review process</p></li>
<li><p>Email notifications for expiring/renewing access to resources</p></li>
<li><p>Ability to define custom attributes on resources and allocations</p></li>
<li><p>Integration with 3rd party systems for automation, access control, and other system provisioning tasks</p></li>
</ul>
</div></blockquote>
</section>
<section id="principal-investigators-pis-or-project-owners">
<h2>Principal investigators (PIs) or Project Owners:<a class="headerlink" href="#principal-investigators-pis-or-project-owners" title="Link to this heading"></a></h2>
<p>Principal investigators (PIs) can use ColdFront as a self-service portal to do the following tasks:</p>
<blockquote>
<div><ul class="simple">
<li><p>Request allocations to center sources such as clusters, cloud resources, servers, storage, and software licenses</p></li>
<li><p>Add/remove user access to/from allocated resources without requiring system administrator interaction</p></li>
<li><p>Elevate selected users to ‘manager’ status, allowing them to handle some of the PI tasks such as request new and renew expiring resource allocations, add/remove users to/from resource allocations, add project data such as grants and publications</p></li>
<li><p>Monitor resource utilization such as storage and cloud usage</p></li>
<li><p>Receive email notifications for expiring/renewing access to resources as well as notifications when allocations change status - i.e. activated, expired, denied</p></li>
<li><p>Provide information such as grants, publications, and other reportable data for periodic review by center director to demonstrate need for the resources</p></li>
</ul>
</div></blockquote>
</section>
<section id="hpc-system-administrators">
<h2>HPC system administrators:<a class="headerlink" href="#hpc-system-administrators" title="Link to this heading"></a></h2>
<p>HPC system administrators can use ColdFront as a management portal and a command line tool to complete the following tasks:</p>
<blockquote>
<div><ul class="simple">
<li><p>Approve/deny resource allocation requests</p></li>
<li><p>Define when a resource allocation will expire</p></li>
<li><p>Associate attributes with resources and allocations for access control automation</p></li>
<li><p>Automate job scheduler account management by utilizing attributes on resources and allocations (currently supports the Slurm job scheduler)</p></li>
<li><p>Manage availability of resources. Resources can be public or private. Private resources can be made available on per-user or per-group basis</p></li>
<li><p>Require PIs to periodically review their projects to ensure user access is kept up to date which helps keep systems secure and data protected</p></li>
<li><p>Integrate with multiple authentication options such as local database, LDAP, or OpenIdConnect (FreeIPA-based)</p></li>
</ul>
</div></blockquote>
</section>
<section id="center-directors">
<h2>Center directors:<a class="headerlink" href="#center-directors" title="Link to this heading"></a></h2>
<p>Center directors can use ColdFront to do the following:</p>
<blockquote>
<div><ul class="simple">
<li><p>Measure center impact based on grants, publications, and other research output entered by PIs</p></li>
<li><p>Collect return on investment metrics to position HPC center for sustainability</p></li>
<li><p>Interact with PIs on project reviews ensuring they provide all required information</p></li>
<li><p>Periodically review PI access to center resources</p></li>
<li><p>Explore all projects, resource allocations, grants, and publications with read only access</p></li>
</ul>
</div></blockquote>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="workshop.html" class="btn btn-neutral float-left" title="Workshop" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="powersaving.html" class="btn btn-neutral float-right" title="Electrical Energy Saving" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, MAI.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>